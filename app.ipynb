{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/http://coursera-university-assets.s3.amazonaws.com/4a/cb36835ae3421187080898a7ecc11d/Google-G_360x360.png?auto=format%2Ccompress&dpr=1&w=56px&h=56px&auto=format%2Ccompress&dpr=1&w=&h=\">\n",
    "\n",
    "## Google Data Analytics Capstone\n",
    "\n",
    "<div style=\"clear: both\"></div>\n",
    "<hr style=\"width:420px; margin: auto; float: left\" />\n",
    "\n",
    "<div style=\"clear: both\"></div>\n",
    "<div style=\"clear: both\"></div>\n",
    "<hr style=\"width:420px; margin: auto; float: left\" />\n",
    "\n",
    "<div style=\"clear: both\"></div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<h3>Abdulrahman Alazwari</h3>\n",
    "<a href=\"https://github.com/azwri/\">\n",
    "    <img src='logos/github-logo.png' width='30'  />\n",
    "</a><span> &nbsp;&nbsp;&nbsp; </span><a href=\"https://www.linkedin.com/in/abdulrahman-alazwari/\">\n",
    "    <img src='logos/linkedin-logo.png' width='30' />\n",
    "</a><span> &nbsp;&nbsp;&nbsp; </span><a href=\"https://twitter.com/Al_Azwari\">\n",
    "    <img src='logos/twitter-logo.png' width='30' />\n",
    "</a><span> &nbsp;&nbsp;&nbsp; </span><a href = \"mailto: aazwri@gmail.com\">\n",
    "    <img src='logos/gmail-logo.png' width='40' />\n",
    "</a>\n",
    "<br><br>\n",
    "<div style=\"clear: both\"></div>\n",
    "<hr style=\"width:220px; margin: auto; float: left\" />\n",
    "\n",
    "<div style=\"clear: both\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries\n",
    "> if error download the below<br>\n",
    ">> !pip install arabic-reshaper<br>\n",
    ">> !pip install python-bidi<br>\n",
    ">> !pip install folium<br>\n",
    ">> !pip install wordcloud<br>\n",
    ">> !pi install pillow<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15484/3286955613.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfolium\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "# !pip install arabic-reshaper\n",
    "# !pip install python-bidi\n",
    "# !pip install folium\n",
    "# !pip install wordcloud\n",
    "# !pip install pillow\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pylab as plt\n",
    "import folium\n",
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "\n",
    "%matplotlib inline\n",
    "# disable chained assignments\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather Data\n",
    "\n",
    "Download the CSV file from [source link](https://datasource.kapsarc.org/explore/dataset/saudi-arabia-coronavirus-disease-covid-19-situation/export/?sort=-daily_accumulative&dataChart=%3D&disjunctive.daily_accumulative=&flg=ar&disjunctive.city&disjunctive.daily_cumulative&disjunctive.indicator&disjunctive.event&disjunctive.region&disjunctive.city_en&disjunctive.region_en).<br/>\n",
    "* The csv file is more than 19 GB right now, June 2021.<br/>\n",
    "* First download the file and read it by `pandas.read_csv` method and pass argument `;` to `sep` parameter, because they format the csv file by `;`.<br/>\n",
    "* Second use a tricky way to lower the size of CSV file to be about 2 GB:\n",
    "> Save the file by `to_csv` method and pass argument `gzip` extension to `compression` parameter to compress the file and lower the size, and importantly pass `False` to index parameter to exclude the index column.<br/>\n",
    "> For memory reason delete the orginal CSV file by `os.remove` method.<br/>\n",
    "> Read the new file by `pandas.read_csv` method and pass argument `gzip` to `compression` parameter.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_file = pd.read_csv('saudi-arabia-coronavirus-disease-covid-19-situation.csv', sep=';')\n",
    "# csv_file.to_csv('sa-covid-19-v1.csv', compression='gzip', index=False)\n",
    "# os.remove('saudi-arabia-coronavirus-disease-covid-19-situation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read CSV file and assign it to `df`os.remove variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sa-covid-19-v1.csv', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Data\n",
    "\n",
    "> Use `head` method to have a look on the first 5 observations.<br/>\n",
    "> Use `columns.values` property to return the columns names.<br/>\n",
    "> Use `info` meethod to see missing values and data types of each feature.<br/>\n",
    "> Also we can use `dtype` property to see the data types.<br/>\n",
    "> Summary statistics on numeric values by using `describe` method.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data\n",
    "> Make a data frame copy to manipulate the data<br>\n",
    "> Filter on `daliy` cases from `Daily / Cumulative` column<br>\n",
    "> Drop attributes, which we do not need `Daily / Cumulative` and `Event`<br>\n",
    "> Convert columns names to lower case to use it as attribute when call it<br>\n",
    "> Rename last attribute `cases (person)` to `cases`<br>\n",
    "> Drop unnecessary record (“Total”)\n",
    "> Assign total_record variable to `Total` record and total_record_index variable to indexes of total_record<br>\n",
    "> Check missing values, and drip them or change them<br>\n",
    "> Chenge data type of case attribute and chenge data type of date attribute<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy from the orginal dataframe\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter on `daliy` cases from `Daily / Cumulative` column\n",
    "df_copy = df[df_copy['Daily / Cumulative'] == 'Daily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop attributes, which we do not need `Daily / Cumulative` and `Event`\n",
    "df_copy.drop(['Daily / Cumulative', 'Event'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the columns after drop\n",
    "df_copy.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert columns names to lower case to use it as attribute when call it\n",
    "# rename last attribute `cases (person)` to `cases`\n",
    "df_copy.rename(columns=lambda col: col.lower(), inplace=True)\n",
    "df_copy.rename(columns={'cases (person)': 'cases'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the columns after convert to lower case and rename `cases (person)` to `case`\n",
    "df_copy.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary record (“Total”)\n",
    "# assign total_record variable to `Total` record and total_record_index variable to indexes of total_record\n",
    "# print(how many record with total value)\n",
    "total_record = df_copy[df_copy.city == 'Total']\n",
    "total_record_index = total_record.index.tolist()\n",
    "len(total_record_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the `Total` record\n",
    "df_copy.drop(total_record_index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data frame after drop `Total` records\n",
    "df_copy[df_copy.city == 'Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values\n",
    "df_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check format\n",
    "df_copy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chenge data type of case attribute and chenge data type of date attribute, then check format again\n",
    "df_copy.cases.astype('int')\n",
    "df_copy['date'] = pd.to_datetime(df_copy['date'])\n",
    "df_copy.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a New Data Frame after Changing, one normal and the other is compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.to_csv('sa-covid-19-v2.csv', index=False)\n",
    "df_copy.to_csv('sa-covid-19-v2-compressed.csv', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics: Indicator vs. Cases, then:\n",
    "> ### Split by indicator\n",
    ">> ### make four data frames for each\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.indicator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = df_copy.query(\"indicator == 'Cases'\").reset_index(drop=True)\n",
    "recoveries = df_copy.query(\"indicator == 'Recoveries'\").reset_index(drop=True)\n",
    "active = df_copy.query(\"indicator == 'Active'\").reset_index(drop=True)\n",
    "mortalities = df_copy.query(\"indicator == 'Mortalities'\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping Data:\n",
    "> ### Indicator vs.Region vs. Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.groupby(['indicator', 'region']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning:\n",
    "> I choose this websit to make levels as below\n",
    "https://www.cdc.gov/coronavirus/2019-ncov/travelers/how-level-is-determined.html\n",
    "\n",
    "<img src=\"logos/levels.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make function for binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this funcation take one parameter then return level depending on the conditions below\n",
    "def level(val):\n",
    "    if val < 49:\n",
    "        return 'LOW'\n",
    "    elif val < 99:\n",
    "        return 'MODERATE'\n",
    "    elif val <= 500:\n",
    "        return 'HIGH'\n",
    "    else:\n",
    "        return 'VERY HIGH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns to the cases data frame for binning\n",
    "# Below, pass the function level to apply function\n",
    "# apply function will put bin for each record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases['cases_binned'] = cases.cases.apply(level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases.cases_binned.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning for cases\n",
    "cases.cases_binned.value_counts().plot(kind='pie', figsize=(10, 7))\n",
    "plt.title(\"Daliy Cases Levels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line Plot\n",
    "> #### Use line plot to draw a line for every week and only “Cases” Parameters: Every Week + Indicator: Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases['week'] = cases['date'].map(lambda x: x.isocalendar()[1])\n",
    "cases['month'] = pd.DatetimeIndex(cases['date']).month\n",
    "cases['year'] = cases['date'].map(lambda x: x.isocalendar()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cases[cases.year == 2020].groupby('week').sum()['cases'].sort_index().plot(figsize=(20, 5))\n",
    "plt.yticks([ 1000, 5000, 10000, 15000, 20000, 25000, 30000], [ '2.5K', '5K', '10K', '15K', '20K', '25K', '30K'])\n",
    "plt.xticks([0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55], \n",
    "           ['Week 1', 'Week 5', 'Week 10', 'Week 15', 'Week 20', 'Week 25', 'Week 30', 'Week 35', 'Week 40', 'Week 45', 'Week 50','Year 2021'])\n",
    "plt.title(\"COVID-19 Weekly Cases - 2020\")\n",
    "plt.xlabel(\"Week Number\")\n",
    "plt.ylabel(\"Number Of Cases\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases[(cases.year == 2020) & (cases.month.notna())].groupby('month').sum()['cases'].sort_index().plot(figsize=(20, 5))\n",
    "plt.yticks([0, 20000, 40000, 60000, 80000, 100000, 120000], ['0', '20K', '40K', '60K', '80K', '100K', '120K'])\n",
    "plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], \n",
    "           ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov','Dec'])\n",
    "plt.title(\"COVID-19 Monthly Cases - 2020\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Number Of Cases\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cases[cases.year == 2021].groupby('week').sum()['cases'].sort_index().plot(figsize=(20, 5))\n",
    "plt.yticks([0, 1000, 5000, 10000, 15000, 20000, 25000, 30000], ['0', '1K', '5K', '10K', '15K', '20K', '25K', '30K'])\n",
    "plt.xticks([0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55], \n",
    "           ['Week 1', 'Week 5', 'Week 10', 'Week 15', 'Week 20', 'Week 25', 'Week 30', 'Week 35', 'Week 40', 'Week 45', 'Week 50','Year 2022'])\n",
    "plt.title(\"COVID-19 Weekly Cases - 2021\")\n",
    "plt.xlabel(\"Week Number\")\n",
    "plt.ylabel(\"Number Of Cases\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases[(cases.year == 2021) & (cases.month.notna())].groupby('month').sum()['cases'].sort_index().plot(figsize=(20, 5))\n",
    "plt.yticks([0, 20000, 40000, 60000, 80000, 100000, 120000], ['0', '20K', '40K', '60K', '80K', '100K', '120K'])\n",
    "plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], \n",
    "           ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov','Dec'])\n",
    "plt.title(\"COVID-19 Monthly Cases - 2021\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Number Of Cases\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Plot\n",
    "> #### Use area plot to draw a Top 5: Total Cases Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_city = cases.groupby('city').sum()[['cases']].sort_values(by='cases', ascending=False)[:5].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_city = top_5_city.append([top_5_city]*5,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_city.plot(kind='area', figsize=(20, 10))\n",
    "plt.title('Top 5 Cites Cases')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pie Chart\n",
    "> #### Use Pie chart to draw total cases in regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cases = cases.groupby('region').sum()[['cases']]\n",
    "total_cases.plot(kind='pie', y='cases', figsize=(20, 10), legend=False)\n",
    "plt.title('Regions VS Cases')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Geospatial Data\n",
    "> #### Use Folium Library to draw total cases in regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read `regions.json` file, contains jps coordinates\n",
    "gps_json = pd.read_json('regions.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign `region_cases_en` to regions from te data frame\n",
    "region_cases_en = cases.groupby('region').sum()[['cases']].to_dict()['cases']\n",
    "\n",
    "# create a dictionary `regions_ar` to Arabic region names\n",
    "regions_ar = {\n",
    "    \"Eastern Region\": \"المنطقة الشرقية\",\n",
    "    \"Ar Riyad\":\"منطقة الرياض\",\n",
    "    \"Makkah Al Mukarramah\":\"منطقة مكة المكرمة\",\n",
    "    \"Aseer\":\"منطقة عسير\",\n",
    "    \"Al Qaseem\":\"منطقة القصيم\",\n",
    "    \"Jazan\":\"منطقة جازان\",\n",
    "    \"Al Madinah Al Munawwarah\":\"منطقة المدينة المنورة\",\n",
    "    \"Al Bahah\":\"منطقة الباحة\",\n",
    "    \"Hail\":\"منطقة حائل\",\n",
    "    \"Tabuk\":\"منطقة تبوك\",\n",
    "    \"Najran\":\"منطقة نجران\",\n",
    "    \"Al Jawf\":\"منطقة الجوف\",\n",
    "    \"Northern Borders\":\"منطقة الحدود الشمالية\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary `region_cases_ar` to Arabic & English region names\n",
    "region_cases_ar = {}\n",
    "for i in regions_ar:\n",
    "    region_cases_ar[i] = regions_ar[i]\n",
    "\n",
    "    \n",
    "# create a dictionary `jps_ar` contains Arabic region name and jps coordinates\n",
    "jps_ar = gps_json[['name_ar', 'center']].set_index('name_ar').T.to_dict()\n",
    "\n",
    "region_ar_en = { k:v for k,v in zip(region_cases_ar.values(), region_cases_ar.keys()) }\n",
    "\n",
    "# last variable for Arabic region and jps coordinates\n",
    "center_gps = {}\n",
    "for i in region_ar_en:\n",
    "    center_gps[i] = (jps_ar[i]['center'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_coordinates = {}\n",
    "for i in total_cases.to_dict()['cases'].items():\n",
    "    region_coordinates[i[0]] = [i[0], regions_ar[i[0]], center_gps[regions_ar[i[0]]][0], center_gps[regions_ar[i[0]]][1], region_cases_en[i[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_data_frame = pd.DataFrame(region_coordinates).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for color the icon on map\n",
    "\n",
    "def color(c):\n",
    "    if c < 10000:\n",
    "        return 'green'\n",
    "    elif c < 50000:\n",
    "        return 'lightgreen'\n",
    "    elif c < 100000:\n",
    "        return 'orange'\n",
    "    else:\n",
    "        return 'red'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center = folium.Map(location=[24.7, 46.73333], zoom_start=6, zoom_control=False, scrollWheelZoom=False, dragging=False, tiles='Stamen Terrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = folium.FeatureGroup(name=\"regions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in region_coordinates.items():\n",
    "    \n",
    "    fg.add_child(folium.Marker(location=[i[1][2], i[1][3]], \n",
    "                               popup=folium.Popup(f'{i[1][1]} {i[1][4]} حالة', max_width=len(i[1][1]) * 20), \n",
    "                               icon=folium.Icon(color=color(i[1][4]))))\n",
    "center.add_child(fg)\n",
    "center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choropleth maps\n",
    "> define a function to change names of regions to match the names in geo file.<br>\n",
    "> add new columns to the cases data frame for new region names.<br>\n",
    "> define new data frame for regions_cases to add it as data in Choropleth maps.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def change_region_name(region):\n",
    "    if region == \"Eastern Region\":\n",
    "        return \"Eastern Region\"\n",
    "    elif region == \"Ar Riyad\":\n",
    "        return \"Riyadh\"\n",
    "    elif region == \"Makkah Al Mukarramah\":\n",
    "        return \"Mecca\"\n",
    "    elif region == \"Aseer\":\n",
    "        return \"Asir\"\n",
    "    elif region == \"Al Qaseem\":\n",
    "        return \"Qassim\"\n",
    "    elif region == \"Jazan\":\n",
    "        return \"Jazan\"\n",
    "    elif region == \"Al Madinah Al Munawwarah\":\n",
    "        return \"Medina\"\n",
    "    elif region == \"Al Bahah\":\n",
    "        return \"Al Bahah\"\n",
    "    elif region == \"Hail\":\n",
    "        return \"Hail\"\n",
    "    elif region == \"Tabuk\":\n",
    "        return \"Tabuk\"\n",
    "    elif region == \"Najran\":\n",
    "        return \"Najran\"\n",
    "    elif region == \"Al Jawf\":\n",
    "        return \"Al Jouf\"\n",
    "    elif region == \"Northern Borders\":\n",
    "        return \"Northern Borders\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cases[\"new_region_name\"] = cases['region'].apply(change_region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# regions_cases = cases.groupby(['region'], as_index=False).sum()[[\"region\",\"cases\"]]\n",
    "regions_cases = cases.groupby(['new_region_name'], as_index=False).sum()[[\"new_region_name\",\"cases\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regions_geo_file = 'SA_regions.json'\n",
    "\n",
    "m = folium.Map(location=[24, 46], zoom_start=6, scrollWheelZoom=False, dragging=False)\n",
    "\n",
    "folium.Choropleth(\n",
    "    geo_data=regions_geo_file,\n",
    "    name=\"choropleth\",\n",
    "    data=regions_cases,\n",
    "    columns=[\"new_region_name\", \"cases\"],\n",
    "    key_on=\"feature.properties.name\",\n",
    "    fill_color=\"YlOrRd\",\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name=\"Cases Rate (%)\",\n",
    ").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Cloud\n",
    "> #### Use `wordcloud` Library to draw total cases per city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ksa_map = np.array(Image.open(os.path.join(\"logos/ksa2.png\")))\n",
    "text = cases.city.value_counts().to_dict()\n",
    "text = {t.replace(' ', '').replace('ʻ', '').replace(\"'\", \"\").replace('d͟', 'd').replace('D͟', 'D'): i * 20 for t,i in text.items()}\n",
    "\n",
    "\n",
    "\n",
    "def transform_format(val):\n",
    "    if val == 0:\n",
    "        return 255\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.add(\"said\")\n",
    "    \n",
    "# Transform your mask into a new one that will work with the function:\n",
    "transformed_ksa_map = np.ndarray((ksa_map.shape[0],ksa_map.shape[1]), np.int32)\n",
    "\n",
    "for i in range(len(ksa_map)):\n",
    "    transformed_ksa_map[i] = list(map(transform_format, ksa_map[i]))\n",
    "\n",
    "    \n",
    "# Create a word cloud image\n",
    "wc = WordCloud(background_color=\"white\", max_words=1000, mask=transformed_ksa_map,\n",
    "               stopwords=stopwords, contour_width=0, contour_color='firebrick')\n",
    "\n",
    "# Generate a wordcloud\n",
    "wc.generate_from_frequencies(text)\n",
    "\n",
    "# store to file\n",
    "wc.to_file(\"logos/ksa3.png\")\n",
    "\n",
    "# show\n",
    "plt.figure(figsize=[25,12])\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# translate cities to arabic\n",
    "arabic = {'ArRiyad' : 'الرياض',\n",
    " 'Jeddah': 'جده',\n",
    " 'MakkahAlMukarramah': 'مكة المكرمة',\n",
    " 'AdDammam': 'الدمام',\n",
    " 'AlMadinahAlMunawwarah': 'المدينة المنورة',\n",
    " 'AlHufuf': 'الهفوف',\n",
    " 'AtTaʼIf': 'الطايف',\n",
    " 'AdHDHahran': 'الظهران',\n",
    " 'Buraydah': 'بريدة',\n",
    " 'AlQatif': 'القطيف',\n",
    " 'AlKhubar': 'الخبر',\n",
    " 'KhamisMushayt': 'خميس مشيط',\n",
    " 'Tabuk': 'تبوك',\n",
    " 'Yanbu': 'ينبع',\n",
    " 'HaʼIl': 'حائل',\n",
    " 'AlJubayl': 'الجبيل',\n",
    " 'Najran': 'نجران',\n",
    " 'Abha': 'ابها',\n",
    " 'WadiAdDawasir': 'وادي الدواسر',\n",
    " 'AlKharj': 'الخرج',\n",
    " 'AlMubarraz': 'المبرز',\n",
    " 'Unayzah': 'عنيزة',\n",
    " 'ArAr': 'عرعر',\n",
    " 'AlMajmaAh': 'المجمعة',\n",
    " 'Jazan': 'جازان',\n",
    " 'Buqayq': 'بقيق',\n",
    " 'AnNuAyriyyah': 'النعيرية',\n",
    " 'AdDilam': 'الدلم',\n",
    " 'HafarAlBatin': 'حفر الباطن',\n",
    " 'HawtatBaniTamim': 'حوطة بني تميم',\n",
    " 'AlKhafji': 'الخفجي',\n",
    " 'AzZulfi': 'الزلفي',\n",
    " 'Billasmar': 'بللسمر',\n",
    " 'AdDuwadimi': 'الدوادمي',\n",
    " 'AlMidhnab': 'المذنب',\n",
    " 'Biljurashi': 'بلجرشي',\n",
    " 'AlQunfudhah': 'القنفذة',\n",
    " 'Bishah': 'بيشة',\n",
    " 'AlAsyah': 'الاسياح',\n",
    " 'Sikaka': 'سكاكا',\n",
    " 'Duruma': 'ضرما',\n",
    " 'AlBahah': 'الباحة',\n",
    " 'Khulays': 'خليص',\n",
    " 'Sharurah': 'شرورة',\n",
    " 'UyunAlJiwaʼ': 'عين الجواء',\n",
    " 'QaryatAlUlya': 'قرية العليا',\n",
    " 'DHahranAlJanub': 'ظهران الجنوب',\n",
    " 'RiyadAlKhabraʼ': 'رياض الخبراء',\n",
    " 'AlQurayyat': 'القريات',\n",
    " 'Afif': 'عفيف',\n",
    " 'AlJafr': 'الجفر',\n",
    " 'AlLith': 'الليث',\n",
    " 'RasTannurah': 'رأس تنورة',\n",
    " 'AlBadaʼI': 'البدائع',\n",
    " 'Baysh': 'بيش',\n",
    " 'RafaIAlJamsh': 'رفائع الجمش',\n",
    " 'Mahayil': 'محايل عسير',\n",
    " 'AbuArish': 'ابو عريش',\n",
    " 'RijalAlMa': 'رجال المع',\n",
    " 'AlBukayriyyah': 'البكيرية',\n",
    " 'Mulayjah': 'مليجة',\n",
    " 'AlMikhwah': 'المخواة',\n",
    " 'AhadRifaydah': 'احد رفيدة',\n",
    " 'Khaybar': 'خيبر',\n",
    " 'AlQuwayIyyah': 'القويعية',\n",
    " 'AlKhurmah': 'الخرمة',\n",
    " 'Sabya': 'صبيا',\n",
    " 'MihdAdhDhahab': 'مهد الذهب',\n",
    " 'AlKamil': 'الكامل',\n",
    " 'Samtah': 'صامطة',\n",
    " 'Adam': 'أضم',\n",
    " 'ArRass': 'الرس',\n",
    " 'Safwá': 'صفوى',\n",
    " 'Rafha': 'رفحاء',\n",
    " 'AlAqiq': 'العقيق',\n",
    " 'AlIs': 'العيص',\n",
    " 'Shaqraʼ': 'شقراء',\n",
    " 'AdDirIyyah': 'الديرة',\n",
    " 'AlMudHaylif': 'المظيلف',\n",
    " 'Umlujj': 'املج',\n",
    " 'AlHinakiyyah': 'الحناكية',\n",
    " 'AsSulayyil': 'السليل',\n",
    " 'AlUyun': 'االعلا',\n",
    " 'AlHarajah': 'الحرجة',\n",
    " 'AnNamas': 'النماص',\n",
    " 'AlMuzahimiyyah': 'المزاحمية',\n",
    " 'Turayf': 'طريف',\n",
    " 'Turuba': 'تربه',\n",
    " 'AdDarb': 'الدرب',\n",
    " 'Tabarjal': 'طبرجل',\n",
    " 'AlBashayer': 'البشاير',\n",
    " 'Fayfa': 'فيفا',\n",
    " 'AhadAlMusarihah': 'احد المسارحة',\n",
    " 'AlUla': 'العلا',\n",
    " 'AlIdabi': 'العيدابي',\n",
    " 'Huraymilaʼ': 'حريملاء',\n",
    " 'Qusaybaʼ': 'قصيباء',\n",
    " 'AtTuwal': 'الطوال',\n",
    " 'SaratAbidah': 'سراة عبيدة',\n",
    " 'AlQaysumah': 'القيصومة',\n",
    " 'AshShinan': 'الشنانة',\n",
    " 'WadiAlFara': 'وادي الفرع',\n",
    " 'BadrAlJanub': 'بدر الجنوب',\n",
    " 'SabtAlAlayah': 'سبت العلايه',\n",
    " 'Tumayr': 'تمير',\n",
    " 'Mawqaq': 'موقق',\n",
    " 'Bariq': 'بارق',\n",
    " 'AlBijadiyyah': 'البجادية',\n",
    " 'AlQuwarah': 'القوارة',\n",
    " 'AlAridah': 'العارضة',\n",
    " 'AlMajardah': 'المجاردة',\n",
    " 'Duba': 'ضبا',\n",
    " 'Bathaʼ': 'بطحاء',\n",
    " 'Ranyah': 'رنية',\n",
    " 'UrayIrah': 'عريعرة',\n",
    " 'AlMuwayh': 'المويه',\n",
    " 'Rabigh': 'رابغ',\n",
    " 'HawtatSudayr': 'حوطة سدير',\n",
    " 'Tabalah': 'تبالة',\n",
    " 'Tathlith': 'تثليث',\n",
    " 'Yadamah': 'يدمه',\n",
    " 'Sajir': 'ساجر',\n",
    " 'AlMandaq': 'المندق',\n",
    " 'AlQari': 'القري',\n",
    " 'DawmatAlJandal': 'دومة الجندل',\n",
    " 'AlQahmah': 'القحمة',\n",
    " 'Qilwah': 'قلوة',\n",
    " 'ArRuwaydah': '',\n",
    " 'AlGouz': 'القوز',\n",
    " 'ArRayth': 'الريث',\n",
    " 'AlBad': '',\n",
    " 'AlHajrah': 'الحجرة',\n",
    " 'AshShamli': 'الشملي',\n",
    " 'Laylá': 'ليلى',\n",
    " 'AlHaʼIt': 'الحائط',\n",
    " 'BaqAʼ': 'بقعاء',\n",
    " 'AlArtawiyyah': 'الارطاوية',\n",
    " 'UqlatAsSuqur': 'عقلة الصقور',\n",
    " 'Thurayban': 'ثريبان',\n",
    " 'AlGhazalah': 'الغزالة',\n",
    " 'Numarah': 'نمره',\n",
    " 'AlMaddah': '',\n",
    " 'Hubuna': 'حبونا',\n",
    " 'AdDaʼIr': 'الداير',\n",
    " 'Dariyyah': '',\n",
    " 'AlBirk': 'البرك',\n",
    " 'AnNabhaniyyah': 'النبهانية',\n",
    " 'Khubash': '',\n",
    " 'Thadiq': 'ثادق',\n",
    " 'Rumah': 'رماح',\n",
    " 'UmmAdDawm': 'ام الدوم',\n",
    " 'AlHamnah': '',\n",
    " 'AlQara': 'القرى',\n",
    " 'Haql': 'حقل',\n",
    " 'AlWajh': 'الوجه',\n",
    " 'Taymaʼ': 'تيماء',\n",
    " 'Qiya': 'قيا',\n",
    " 'ArRayn': '',\n",
    " 'AlFarshah': 'الفرشه',\n",
    " 'AlSehen': '',\n",
    " 'Tanumah': 'تنومه',\n",
    " 'AlShoBah': '',\n",
    " 'WadiIbnHashbal': 'وادي بن هشبل',\n",
    " 'AlHadithahBorderStation': 'الحديثة',\n",
    " 'AlMuwassam': 'الموسم',\n",
    " 'AlHarth': 'الحرث',\n",
    " 'AbuRakah': 'ابو راكه',\n",
    " 'Damad': 'ضمد',\n",
    " 'Samiraʼ': 'سميرة',\n",
    " 'Marat': 'مرات',\n",
    " 'DHalm': 'ضلم',\n",
    " 'Farasan': 'فرسان',\n",
    " 'Badr': 'بدر',\n",
    " 'Maysan': 'ميسان',\n",
    " 'Wuthaylan': 'وثيلان',\n",
    " 'Salwá': 'سلوى',\n",
    " 'AlMahani': 'المحاني',\n",
    " 'AlKhasirah': 'الخاصرة',\n",
    " 'AlHariq': 'الحريق',\n",
    " 'AlUwayqilah': '',\n",
    " 'Thuwal': 'ثول',\n",
    " 'BaniHasan': 'بني حسن',\n",
    " 'AsSuAyyirah': '',\n",
    " 'Tarj': 'ترج',\n",
    " 'AlGhat': 'الغاط',\n",
    " 'Thar': 'ثار',\n",
    " 'AsSulaymi': 'السليمي',\n",
    " 'Shuwaq': 'الشواق',\n",
    " 'AdhDhibiyyah': '',\n",
    " 'Sayhat': 'سيهات',\n",
    " 'AbuAjram': 'أبو عجرم',\n",
    " 'AlHada': 'الهدا',\n",
    " 'Nifi': 'نفي',\n",
    " 'Mayqu': 'ميقوع',\n",
    " 'JudayyidatArAr': 'جديدة عرعر',\n",
    " 'AsSufairy': 'الصفيري',\n",
    " 'Hadda': 'حدة',\n",
    " 'HazmAlJalamid': 'حزم الجلاميد',\n",
    " 'Suwayr': 'صوير',\n",
    " 'ArRuqI': 'الرقه',\n",
    " 'AbuUrwah': 'ابو عروة',\n",
    " 'Harad': 'حرض',\n",
    " 'AsSulaymaniyyah': 'السليمانية',\n",
    " 'HadadBaniMalik': 'حداد بني ماالك',\n",
    " 'AlHadban': 'الحدبان',\n",
    " 'Samudah': 'سامودة'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make dictionary for arabic city and cases\n",
    "cases_arabic_city = {}\n",
    "cases_arabic_only_city = {}\n",
    "for i in text:\n",
    "    cases_arabic_city[i] = [i, arabic[i], text[i]]\n",
    "    cases_arabic_only_city[arabic[i]] = text[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "ksa_map = np.array(Image.open(os.path.join(\"logos/ksa2.png\")))\n",
    "text_1 = cases_arabic_only_city\n",
    "text_1 = {get_display(arabic_reshaper.reshape(t)): i * 20 for t,i in text_1.items()}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Transform your mask into a new one that will work with the function:\n",
    "transformed_ksa_map = np.ndarray((ksa_map.shape[0],ksa_map.shape[1]), np.int32)\n",
    "\n",
    "for i in range(len(ksa_map)):\n",
    "    transformed_ksa_map[i] = list(map(transform_format, ksa_map[i]))\n",
    "\n",
    "    \n",
    "# Create a word cloud image\n",
    "wc = WordCloud(background_color=\"white\", max_words=1000, mask=transformed_ksa_map,\n",
    "               stopwords=stopwords, contour_width=0, contour_color='firebrick', font_path='logos/NotoNaskhArabic-Regular.ttf')\n",
    "\n",
    "# Generate a wordcloud\n",
    "wc.generate_from_frequencies(text_1)\n",
    "\n",
    "# store to file\n",
    "wc.to_file(\"logos/ksa4.png\")\n",
    "\n",
    "# show\n",
    "plt.figure(figsize=[25,12])\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
